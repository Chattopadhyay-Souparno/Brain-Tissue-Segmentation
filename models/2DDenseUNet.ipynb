{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMIG5gOwa-Nb"
      },
      "source": [
        "##Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spA2vbr3a0j7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68e706a8-f3a5-49df-99a9-74e6cb1e3767"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting simpleitk\n",
            "  Downloading SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Downloading SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: simpleitk\n",
            "Successfully installed simpleitk-2.4.0\n",
            "TensorFlow version: 2.17.1\n",
            "Keras version: 3.5.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import glob\n",
        "import warnings\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "!pip install simpleitk\n",
        "import SimpleITK as sitk\n",
        "from scipy import ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, Dropout, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, Input\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Keras version:\", keras.__version__)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEFUu8FjYvaz"
      },
      "source": [
        "##Defining the Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eerKWEtxUg_x"
      },
      "outputs": [],
      "source": [
        "# Image Parameters\n",
        "IMAGE_SIZE = (256, 128, 256)\n",
        "\n",
        "# Training, Testing and Validation Parameters\n",
        "TRAINING_VOLUMES = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
        "VALIDATION_VOLUMES = [9]\n",
        "\n",
        "# Hyperparameters\n",
        "N_CLASSES = 4\n",
        "N_INPUT_CHANNELS = 1\n",
        "PATCH_SIZE = (32, 32)\n",
        "PATCH_STRIDE = (32, 32)\n",
        "\n",
        "# Data Preparation Parameters\n",
        "CONTENT_THRESHOLD = 0.3 # To Get Rid of Useless Information in the Image\n",
        "\n",
        "# Training Parameters\n",
        "N_EPOCHS = 1000\n",
        "BATCH_SIZE = 64\n",
        "PATIENCE = 200\n",
        "MODEL_FNAME_PATTERN = 'model.keras'\n",
        "OPTIMISER = 'Adam'\n",
        "LOSS = 'categorical_crossentropy'\n",
        "dropout_rate = 0.40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kakQO5X9E0oR"
      },
      "source": [
        "##Define UNet Architecture"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unet(img_size=PATCH_SIZE, n_classes=N_CLASSES, n_input_channels=N_INPUT_CHANNELS, scale=1):\n",
        "    inputs = keras.Input(shape=img_size + (n_input_channels, ))\n",
        "\n",
        "    # Encoding Path of the DenseUNet (32-64-128-256-512)\n",
        "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conc11 = concatenate([inputs, conv11], axis=3)\n",
        "    conv12 = Conv2D(32, (3, 3), activation='relu', padding='same')(conc11)\n",
        "    conc12 = concatenate([inputs, conv12], axis=3)\n",
        "    drop1 = Dropout(rate=dropout_rate)(conc12, training=True)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(drop1)\n",
        "\n",
        "    conv21 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conc21 = concatenate([pool1, conv21], axis=3)\n",
        "    conv22 = Conv2D(64, (3, 3), activation='relu', padding='same')(conc21)\n",
        "    conc22 = concatenate([pool1, conv22], axis=3)\n",
        "    drop2 = Dropout(rate=dropout_rate)(conc22, training=True)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(drop2)\n",
        "\n",
        "    conv31 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conc31 = concatenate([pool2, conv31], axis=3)\n",
        "    conv32 = Conv2D(128, (3, 3), activation='relu', padding='same')(conc31)\n",
        "    conc32 = concatenate([pool2, conv32], axis=3)\n",
        "    drop3 = Dropout(rate=dropout_rate)(conc32, training=True)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(drop3)\n",
        "\n",
        "    conv41 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conc41 = concatenate([pool3, conv41], axis=3)\n",
        "    conv42 = Conv2D(256, (3, 3), activation='relu', padding='same')(conc41)\n",
        "    conc42 = concatenate([pool3, conv42], axis=3)\n",
        "    drop4 = Dropout(rate=dropout_rate)(conc42, training=True)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv51 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
        "    conc51 = concatenate([pool4, conv51], axis=3)\n",
        "    conv52 = Conv2D(512, (3, 3), activation='relu', padding='same')(conc51)\n",
        "    conc52 = concatenate([pool4, conv52], axis=3)\n",
        "    drop5 = Dropout(rate=dropout_rate)(conc52, training=True)\n",
        "\n",
        "    # Decoding Path of the ResUNet\n",
        "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(drop5), conc42], axis=3)\n",
        "    conv61 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
        "    conc61 = concatenate([up6, conv61], axis=3)\n",
        "    conv62 = Conv2D(256, (3, 3), activation='relu', padding='same')(conc61)\n",
        "    conc62 = concatenate([up6, conv62], axis=3)\n",
        "    drop6 = Dropout(rate=dropout_rate)(conc62, training=True)\n",
        "\n",
        "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(drop6), conv32], axis=3)\n",
        "    conv71 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conc71 = concatenate([up7, conv71], axis=3)\n",
        "    conv72 = Conv2D(128, (3, 3), activation='relu', padding='same')(conc71)\n",
        "    conc72 = concatenate([up7, conv72], axis=3)\n",
        "    drop7 = Dropout(rate=dropout_rate)(conc72, training=True)\n",
        "\n",
        "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(drop7), conv22], axis=3)\n",
        "    conv81 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
        "    conc81 = concatenate([up8, conv81], axis=3)\n",
        "    conv82 = Conv2D(64, (3, 3), activation='relu', padding='same')(conc81)\n",
        "    conc82 = concatenate([up8, conv82], axis=3)\n",
        "    drop8 = Dropout(rate=dropout_rate)(conc82, training=True)\n",
        "\n",
        "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(drop8), conv12], axis=3)\n",
        "    conv91 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
        "    conc91 = concatenate([up9, conv91], axis=3)\n",
        "    conv92 = Conv2D(32, (3, 3), activation='relu', padding='same')(conc91)\n",
        "    conc92 = concatenate([up9, conv92], axis=3)\n",
        "    drop9 = Dropout(rate=dropout_rate)(conc92, training=True)\n",
        "\n",
        "    outputs = Conv2D(n_classes, (1, 1), activation='sigmoid')(drop9)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "wcAmfYyQoM_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z1E1IglE-0w"
      },
      "source": [
        "##Loading the training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgujGm9tX_Rj"
      },
      "outputs": [],
      "source": [
        "def load_data_bias(image_size, setName):\n",
        "    import os\n",
        "    import glob\n",
        "    import numpy as np\n",
        "    import nibabel as nib\n",
        "\n",
        "    # Update the data path based on the new folder structure\n",
        "    data_dir = '/content/drive/MyDrive/Dataset_Final/{}/'.format(setName)\n",
        "    data_pattern = os.path.join(data_dir, 'IBSR_*')\n",
        "\n",
        "    # Get a list of all subject directories\n",
        "    subject_dirs = glob.glob(data_pattern)\n",
        "    n_volumes = len(subject_dirs)\n",
        "\n",
        "    # Initialize arrays to hold the image and label data\n",
        "    volumes = np.zeros((n_volumes, *image_size, 1))\n",
        "    labels = np.zeros((n_volumes, *image_size, 1))\n",
        "\n",
        "    i = 0\n",
        "    for subject_dir in subject_dirs:\n",
        "        # Extract the subject name from the directory path\n",
        "        subject_name = os.path.basename(subject_dir)\n",
        "\n",
        "        # Construct the file paths for the image and segmentation\n",
        "        img_file = os.path.join(subject_dir, '{}.nii.gz'.format(subject_name))\n",
        "        seg_file = os.path.join(subject_dir, '{}_seg.nii.gz'.format(subject_name))\n",
        "\n",
        "        # Load the image data\n",
        "        img_data = nib.load(img_file)\n",
        "        img_array = img_data.get_fdata()\n",
        "        img_array = img_array.reshape((*image_size, 1))\n",
        "        volumes[i] = img_array\n",
        "\n",
        "        # Load the segmentation data\n",
        "        seg_data = nib.load(seg_file)\n",
        "        seg_array = seg_data.get_fdata()\n",
        "        seg_array = seg_array.reshape((*image_size, 1))\n",
        "        labels[i] = seg_array\n",
        "\n",
        "        print(\"Loaded subject: {}\".format(subject_name))\n",
        "        i += 1\n",
        "\n",
        "    return (volumes, labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoSMUWMWgKQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb5bb51-f495-4544-a8d1-8a2b508e98a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded subject: IBSR_18\n",
            "Loaded subject: IBSR_07\n",
            "Loaded subject: IBSR_09\n",
            "Loaded subject: IBSR_08\n",
            "Loaded subject: IBSR_16\n",
            "Loaded subject: IBSR_06\n",
            "Loaded subject: IBSR_05\n",
            "Loaded subject: IBSR_04\n",
            "Loaded subject: IBSR_01\n",
            "Loaded subject: IBSR_03\n",
            "Loaded subject: IBSR_13\n",
            "Loaded subject: IBSR_14\n",
            "Loaded subject: IBSR_11\n",
            "Loaded subject: IBSR_17\n",
            "Loaded subject: IBSR_12\n"
          ]
        }
      ],
      "source": [
        "(t_volumes, t_labels) = load_data_bias(IMAGE_SIZE, 'Training_Set')\n",
        "(v_volumes, v_labels) = load_data_bias(IMAGE_SIZE, 'Validation_Set')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAok6QlCeBm0"
      },
      "source": [
        "##Splitting the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_aGLgc60ceM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28128d33-be24-4621-c769-6571cf4c05d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9, 256, 128, 256, 1)\n",
            "(1, 256, 128, 256, 1)\n"
          ]
        }
      ],
      "source": [
        "# Split the training data into training and validation\n",
        "training_volumes = t_volumes[TRAINING_VOLUMES]\n",
        "training_labels = t_labels[TRAINING_VOLUMES]\n",
        "\n",
        "validation_volumes = t_volumes[VALIDATION_VOLUMES]\n",
        "validation_labels = t_labels[VALIDATION_VOLUMES]\n",
        "\n",
        "print(training_volumes.shape)\n",
        "#print(training_labels.shape)\n",
        "\n",
        "print(validation_volumes.shape)\n",
        "#print(validation_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpKWGJ-Fh1B_"
      },
      "source": [
        "##Extracting Patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMvPbAZ4gb8C"
      },
      "outputs": [],
      "source": [
        "def extract_patches(x, patch_size, patch_stride) :\n",
        "  return tf.image.extract_patches(\n",
        "    x,\n",
        "    sizes=[1, *patch_size, 1],\n",
        "    strides=[1, *patch_stride, 1],\n",
        "    rates=[1, 1, 1, 1],\n",
        "    padding='SAME', name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsKNTm-Lf-sb"
      },
      "outputs": [],
      "source": [
        "def extract_useful_patches(\n",
        "    volumes, labels,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    patch_size=PATCH_SIZE,\n",
        "    stride=PATCH_STRIDE,\n",
        "    threshold=CONTENT_THRESHOLD,\n",
        "    num_classes=N_CLASSES):\n",
        "\n",
        "    volumes = volumes.reshape([-1, image_size[1], image_size[2], 1])\n",
        "    labels = labels.reshape([-1, image_size[1], image_size[2], 1])\n",
        "\n",
        "    vol_patches = extract_patches(volumes, patch_size, stride).numpy()\n",
        "    seg_patches = extract_patches(labels, patch_size, stride).numpy()\n",
        "\n",
        "    vol_patches = vol_patches.reshape([-1, *patch_size, 1])\n",
        "    seg_patches = seg_patches.reshape([-1, *patch_size])\n",
        "\n",
        "    # Create a foreground mask\n",
        "    foreground_mask = seg_patches != 0\n",
        "\n",
        "    # Select patches with sufficient foreground content\n",
        "    useful_patches = foreground_mask.sum(axis=(1, 2)) > threshold * np.prod(patch_size)\n",
        "\n",
        "    vol_patches = vol_patches[useful_patches]\n",
        "    seg_patches = seg_patches[useful_patches]\n",
        "\n",
        "    # Convert segmentation patches to categorical labels\n",
        "    seg_patches = tf.keras.utils.to_categorical(seg_patches, num_classes=N_CLASSES)\n",
        "    seg_patches = seg_patches.astype('float32')  # Ensure the dtype is float32 if needed\n",
        "\n",
        "    return (vol_patches, seg_patches)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTcoEi426bfg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8739a02-e5d6-4072-cb5a-335b25c3026c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11673, 32, 32, 1)\n"
          ]
        }
      ],
      "source": [
        "# extract patches from training set\n",
        "(training_patches, training_patches_seg) = extract_useful_patches(training_volumes, training_labels)\n",
        "\n",
        "# extract patches from validation set\n",
        "(validation_patches, validation_patches_seg) = extract_useful_patches(validation_volumes, validation_labels)\n",
        "\n",
        "print(training_patches.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx9fsloJgxrm"
      },
      "source": [
        "##Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Degree of Augmentation\n",
        "deg     = 0.2\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40, #40\n",
        "        width_shift_range=deg,\n",
        "        height_shift_range=deg,\n",
        "        # rescale=1./255,\n",
        "        shear_range=deg,\n",
        "        zoom_range=deg,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        fill_mode='nearest') #reflect, wrap, constant(black)"
      ],
      "metadata": {
        "id": "CwyB93VgyuIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6o21TRkXedUO"
      },
      "outputs": [],
      "source": [
        "train_generator = datagen.flow(training_patches, batch_size=int(training_patches.shape[0]/BATCH_SIZE), seed=1)\n",
        "train_label_generator = datagen.flow(training_patches_seg, batch_size=int(training_patches.shape[0]/BATCH_SIZE), seed=1)\n",
        "\n",
        "val_generator = datagen.flow(validation_patches, batch_size=int(validation_patches.shape[0]/BATCH_SIZE), seed=1)\n",
        "val_label_generator = datagen.flow(validation_patches_seg, batch_size=int(validation_patches.shape[0]/BATCH_SIZE), seed=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOw8_p4Oedag"
      },
      "outputs": [],
      "source": [
        "X_train = train_generator.__next__()\n",
        "y_train = train_label_generator.__next__()\n",
        "\n",
        "X_val = val_generator.__next__()\n",
        "y_val = val_label_generator.__next__()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IELRGzM3r2mz",
        "outputId": "0c3b2811-ccf8-4e12-b60a-5924a748e333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11673, 32, 32, 1)\n",
            "(11673, 32, 32, 4)\n",
            "----------------\n",
            "(1074, 32, 32, 1)\n",
            "(1074, 32, 32, 4)\n"
          ]
        }
      ],
      "source": [
        "print(training_patches.shape)\n",
        "print(training_patches_seg.shape)\n",
        "print(\"----------------\")\n",
        "print(validation_patches.shape)\n",
        "print(validation_patches_seg.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce8mcx6Nr3QG",
        "outputId": "95f7232e-6237-4436-df23-a2a6dd56aa7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11855, 32, 32, 1)\n",
            "(11855, 32, 32, 4)\n",
            "(1090, 32, 32, 1)\n",
            "(1090, 32, 32, 4)\n"
          ]
        }
      ],
      "source": [
        "full_train = np.concatenate((training_patches, X_train))\n",
        "print(full_train.shape)\n",
        "full_train_label = np.concatenate((training_patches_seg, y_train))\n",
        "print(full_train_label.shape)\n",
        "\n",
        "full_val = np.concatenate((validation_patches, X_val))\n",
        "print(full_val.shape)\n",
        "full_val_label = np.concatenate((validation_patches_seg, y_val))\n",
        "print(full_val_label.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fdqvKEK1UES"
      },
      "source": [
        "##Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7H9hIPwEwJZ",
        "outputId": "e84d2b6c-fd72-44e4-d564-dc77a815587e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 85ms/step - loss: 2.3068 - val_loss: 0.4488\n",
            "Epoch 2/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.4439 - val_loss: 0.4077\n",
            "Epoch 3/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.3772 - val_loss: 0.3887\n",
            "Epoch 4/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.3388 - val_loss: 0.2959\n",
            "Epoch 5/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.3031 - val_loss: 0.2599\n",
            "Epoch 6/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.2839 - val_loss: 0.2728\n",
            "Epoch 7/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.2581 - val_loss: 0.2448\n",
            "Epoch 8/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.2434 - val_loss: 0.2435\n",
            "Epoch 9/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.2297 - val_loss: 0.2250\n",
            "Epoch 10/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.2219 - val_loss: 0.2382\n",
            "Epoch 11/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.2147 - val_loss: 0.2099\n",
            "Epoch 12/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1999 - val_loss: 0.2262\n",
            "Epoch 13/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1942 - val_loss: 0.2383\n",
            "Epoch 14/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1908 - val_loss: 0.2271\n",
            "Epoch 15/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1839 - val_loss: 0.2114\n",
            "Epoch 16/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.1824 - val_loss: 0.2098\n",
            "Epoch 17/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1804 - val_loss: 0.2156\n",
            "Epoch 18/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.1799 - val_loss: 0.2042\n",
            "Epoch 19/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1682 - val_loss: 0.2045\n",
            "Epoch 20/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.1630 - val_loss: 0.1946\n",
            "Epoch 21/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1602 - val_loss: 0.2190\n",
            "Epoch 22/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1666 - val_loss: 0.2102\n",
            "Epoch 23/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1573 - val_loss: 0.2063\n",
            "Epoch 24/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1548 - val_loss: 0.2188\n",
            "Epoch 25/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1539 - val_loss: 0.2114\n",
            "Epoch 26/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1486 - val_loss: 0.1954\n",
            "Epoch 27/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.1488 - val_loss: 0.1858\n",
            "Epoch 28/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1519 - val_loss: 0.1985\n",
            "Epoch 29/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1453 - val_loss: 0.2039\n",
            "Epoch 30/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1451 - val_loss: 0.1955\n",
            "Epoch 31/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1432 - val_loss: 0.2050\n",
            "Epoch 32/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1419 - val_loss: 0.1885\n",
            "Epoch 33/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1407 - val_loss: 0.2229\n",
            "Epoch 34/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1427 - val_loss: 0.2060\n",
            "Epoch 35/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1347 - val_loss: 0.2060\n",
            "Epoch 36/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1377 - val_loss: 0.2022\n",
            "Epoch 37/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1350 - val_loss: 0.1981\n",
            "Epoch 38/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1351 - val_loss: 0.2198\n",
            "Epoch 39/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1346 - val_loss: 0.1996\n",
            "Epoch 40/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1336 - val_loss: 0.2055\n",
            "Epoch 41/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1334 - val_loss: 0.1952\n",
            "Epoch 42/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1338 - val_loss: 0.2021\n",
            "Epoch 43/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1299 - val_loss: 0.2251\n",
            "Epoch 44/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1287 - val_loss: 0.2009\n",
            "Epoch 45/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1275 - val_loss: 0.2030\n",
            "Epoch 46/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1260 - val_loss: 0.1993\n",
            "Epoch 47/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1251 - val_loss: 0.2146\n",
            "Epoch 48/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1249 - val_loss: 0.2073\n",
            "Epoch 49/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1250 - val_loss: 0.2018\n",
            "Epoch 50/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1244 - val_loss: 0.1954\n",
            "Epoch 51/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1241 - val_loss: 0.2178\n",
            "Epoch 52/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1280 - val_loss: 0.2023\n",
            "Epoch 53/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1220 - val_loss: 0.2042\n",
            "Epoch 54/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1225 - val_loss: 0.2049\n",
            "Epoch 55/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1192 - val_loss: 0.2042\n",
            "Epoch 56/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1257 - val_loss: 0.1995\n",
            "Epoch 57/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1170 - val_loss: 0.1910\n",
            "Epoch 58/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1186 - val_loss: 0.1982\n",
            "Epoch 59/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1204 - val_loss: 0.2267\n",
            "Epoch 60/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1198 - val_loss: 0.2032\n",
            "Epoch 61/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1203 - val_loss: 0.1982\n",
            "Epoch 62/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1184 - val_loss: 0.2042\n",
            "Epoch 63/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1171 - val_loss: 0.1938\n",
            "Epoch 64/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1173 - val_loss: 0.1979\n",
            "Epoch 65/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1158 - val_loss: 0.2012\n",
            "Epoch 66/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1151 - val_loss: 0.2080\n",
            "Epoch 67/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1182 - val_loss: 0.2068\n",
            "Epoch 68/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1162 - val_loss: 0.2036\n",
            "Epoch 69/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1132 - val_loss: 0.2166\n",
            "Epoch 70/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1206 - val_loss: 0.2067\n",
            "Epoch 71/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1139 - val_loss: 0.2142\n",
            "Epoch 72/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1138 - val_loss: 0.2103\n",
            "Epoch 73/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1122 - val_loss: 0.1943\n",
            "Epoch 74/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1134 - val_loss: 0.2074\n",
            "Epoch 75/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1118 - val_loss: 0.2073\n",
            "Epoch 76/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1124 - val_loss: 0.1943\n",
            "Epoch 77/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1118 - val_loss: 0.2046\n",
            "Epoch 78/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1103 - val_loss: 0.2128\n",
            "Epoch 79/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1113 - val_loss: 0.2142\n",
            "Epoch 80/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1112 - val_loss: 0.2035\n",
            "Epoch 81/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1101 - val_loss: 0.2222\n",
            "Epoch 82/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1113 - val_loss: 0.2015\n",
            "Epoch 83/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1104 - val_loss: 0.2029\n",
            "Epoch 84/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1090 - val_loss: 0.2203\n",
            "Epoch 85/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1110 - val_loss: 0.2115\n",
            "Epoch 86/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1086 - val_loss: 0.2002\n",
            "Epoch 87/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1074 - val_loss: 0.1987\n",
            "Epoch 88/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1067 - val_loss: 0.2099\n",
            "Epoch 89/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1058 - val_loss: 0.2192\n",
            "Epoch 90/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1082 - val_loss: 0.2106\n",
            "Epoch 91/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1079 - val_loss: 0.2034\n",
            "Epoch 92/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1063 - val_loss: 0.2261\n",
            "Epoch 93/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1070 - val_loss: 0.2019\n",
            "Epoch 94/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1065 - val_loss: 0.2237\n",
            "Epoch 95/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1064 - val_loss: 0.2087\n",
            "Epoch 96/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1052 - val_loss: 0.1994\n",
            "Epoch 97/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1079 - val_loss: 0.2028\n",
            "Epoch 98/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1084 - val_loss: 0.2118\n",
            "Epoch 99/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1062 - val_loss: 0.2067\n",
            "Epoch 100/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1036 - val_loss: 0.2109\n",
            "Epoch 101/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1052 - val_loss: 0.2039\n",
            "Epoch 102/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1045 - val_loss: 0.2083\n",
            "Epoch 103/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1029 - val_loss: 0.2070\n",
            "Epoch 104/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1043 - val_loss: 0.2149\n",
            "Epoch 105/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1045 - val_loss: 0.2126\n",
            "Epoch 106/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1057 - val_loss: 0.1977\n",
            "Epoch 107/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1024 - val_loss: 0.2096\n",
            "Epoch 108/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1032 - val_loss: 0.2101\n",
            "Epoch 109/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1035 - val_loss: 0.2036\n",
            "Epoch 110/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1018 - val_loss: 0.2016\n",
            "Epoch 111/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1033 - val_loss: 0.2279\n",
            "Epoch 112/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1027 - val_loss: 0.2117\n",
            "Epoch 113/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1002 - val_loss: 0.2147\n",
            "Epoch 114/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1010 - val_loss: 0.2068\n",
            "Epoch 115/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1028 - val_loss: 0.2074\n",
            "Epoch 116/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1015 - val_loss: 0.2035\n",
            "Epoch 117/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1007 - val_loss: 0.2073\n",
            "Epoch 118/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1011 - val_loss: 0.2088\n",
            "Epoch 119/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0995 - val_loss: 0.2238\n",
            "Epoch 120/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1010 - val_loss: 0.2029\n",
            "Epoch 121/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1001 - val_loss: 0.2143\n",
            "Epoch 122/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1003 - val_loss: 0.2055\n",
            "Epoch 123/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1029 - val_loss: 0.2106\n",
            "Epoch 124/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0998 - val_loss: 0.2104\n",
            "Epoch 125/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0994 - val_loss: 0.2069\n",
            "Epoch 126/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0994 - val_loss: 0.2153\n",
            "Epoch 127/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0991 - val_loss: 0.1999\n",
            "Epoch 128/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1021 - val_loss: 0.2137\n",
            "Epoch 129/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1002 - val_loss: 0.2151\n",
            "Epoch 130/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0989 - val_loss: 0.2174\n",
            "Epoch 131/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0996 - val_loss: 0.2218\n",
            "Epoch 132/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0990 - val_loss: 0.2111\n",
            "Epoch 133/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0990 - val_loss: 0.2253\n",
            "Epoch 134/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0981 - val_loss: 0.2107\n",
            "Epoch 135/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0986 - val_loss: 0.2305\n",
            "Epoch 136/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0997 - val_loss: 0.2091\n",
            "Epoch 137/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0983 - val_loss: 0.2051\n",
            "Epoch 138/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0991 - val_loss: 0.2110\n",
            "Epoch 139/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0971 - val_loss: 0.2035\n",
            "Epoch 140/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0981 - val_loss: 0.2129\n",
            "Epoch 141/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1002 - val_loss: 0.2160\n",
            "Epoch 142/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0968 - val_loss: 0.2198\n",
            "Epoch 143/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0976 - val_loss: 0.2119\n",
            "Epoch 144/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0985 - val_loss: 0.2094\n",
            "Epoch 145/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0983 - val_loss: 0.2195\n",
            "Epoch 146/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0983 - val_loss: 0.2088\n",
            "Epoch 147/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0970 - val_loss: 0.1947\n",
            "Epoch 148/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0994 - val_loss: 0.2132\n",
            "Epoch 149/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1011 - val_loss: 0.2021\n",
            "Epoch 150/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0966 - val_loss: 0.2082\n",
            "Epoch 151/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0942 - val_loss: 0.2148\n",
            "Epoch 152/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0966 - val_loss: 0.2157\n",
            "Epoch 153/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0966 - val_loss: 0.2178\n",
            "Epoch 154/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0977 - val_loss: 0.2062\n",
            "Epoch 155/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0960 - val_loss: 0.2242\n",
            "Epoch 156/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0955 - val_loss: 0.2080\n",
            "Epoch 157/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0960 - val_loss: 0.2106\n",
            "Epoch 158/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0950 - val_loss: 0.2112\n",
            "Epoch 159/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0954 - val_loss: 0.2071\n",
            "Epoch 160/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0948 - val_loss: 0.2035\n",
            "Epoch 161/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0950 - val_loss: 0.2080\n",
            "Epoch 162/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0949 - val_loss: 0.2121\n",
            "Epoch 163/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0952 - val_loss: 0.2059\n",
            "Epoch 164/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0937 - val_loss: 0.2041\n",
            "Epoch 165/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0951 - val_loss: 0.2160\n",
            "Epoch 166/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0962 - val_loss: 0.2180\n",
            "Epoch 167/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0949 - val_loss: 0.2214\n",
            "Epoch 168/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0942 - val_loss: 0.2130\n",
            "Epoch 169/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0950 - val_loss: 0.2029\n",
            "Epoch 170/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0959 - val_loss: 0.2109\n",
            "Epoch 171/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0939 - val_loss: 0.2104\n",
            "Epoch 172/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0942 - val_loss: 0.2100\n",
            "Epoch 173/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0934 - val_loss: 0.2167\n",
            "Epoch 174/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0933 - val_loss: 0.2155\n",
            "Epoch 175/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0947 - val_loss: 0.2216\n",
            "Epoch 176/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0951 - val_loss: 0.2103\n",
            "Epoch 177/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0937 - val_loss: 0.2140\n",
            "Epoch 178/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0927 - val_loss: 0.2132\n",
            "Epoch 179/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0939 - val_loss: 0.2148\n",
            "Epoch 180/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0949 - val_loss: 0.2020\n",
            "Epoch 181/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0937 - val_loss: 0.2095\n",
            "Epoch 182/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0923 - val_loss: 0.2017\n",
            "Epoch 183/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0923 - val_loss: 0.2327\n",
            "Epoch 184/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0951 - val_loss: 0.2377\n",
            "Epoch 185/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0923 - val_loss: 0.2002\n",
            "Epoch 186/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0943 - val_loss: 0.2123\n",
            "Epoch 187/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0925 - val_loss: 0.2005\n",
            "Epoch 188/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0965 - val_loss: 0.2198\n",
            "Epoch 189/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0939 - val_loss: 0.2244\n",
            "Epoch 190/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0914 - val_loss: 0.2144\n",
            "Epoch 191/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0934 - val_loss: 0.2278\n",
            "Epoch 192/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0920 - val_loss: 0.2158\n",
            "Epoch 193/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0911 - val_loss: 0.2238\n",
            "Epoch 194/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0907 - val_loss: 0.2151\n",
            "Epoch 195/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0913 - val_loss: 0.2263\n",
            "Epoch 196/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0914 - val_loss: 0.2299\n",
            "Epoch 197/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0928 - val_loss: 0.2129\n",
            "Epoch 198/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0910 - val_loss: 0.2145\n",
            "Epoch 199/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0922 - val_loss: 0.2005\n",
            "Epoch 200/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0935 - val_loss: 0.2115\n",
            "Epoch 201/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0897 - val_loss: 0.2095\n",
            "Epoch 202/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0910 - val_loss: 0.2301\n",
            "Epoch 203/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0919 - val_loss: 0.2083\n",
            "Epoch 204/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0910 - val_loss: 0.2109\n",
            "Epoch 205/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0910 - val_loss: 0.2178\n",
            "Epoch 206/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0912 - val_loss: 0.2079\n",
            "Epoch 207/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0919 - val_loss: 0.2096\n",
            "Epoch 208/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0907 - val_loss: 0.2135\n",
            "Epoch 209/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0921 - val_loss: 0.2105\n",
            "Epoch 210/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0900 - val_loss: 0.2206\n",
            "Epoch 211/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0916 - val_loss: 0.2175\n",
            "Epoch 212/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0922 - val_loss: 0.2185\n",
            "Epoch 213/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0921 - val_loss: 0.2242\n",
            "Epoch 214/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0907 - val_loss: 0.2101\n",
            "Epoch 215/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0912 - val_loss: 0.2221\n",
            "Epoch 216/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0888 - val_loss: 0.2144\n",
            "Epoch 217/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0896 - val_loss: 0.2032\n",
            "Epoch 218/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0911 - val_loss: 0.2138\n",
            "Epoch 219/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0912 - val_loss: 0.2162\n",
            "Epoch 220/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0915 - val_loss: 0.2047\n",
            "Epoch 221/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1013 - val_loss: 0.2151\n",
            "Epoch 222/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0903 - val_loss: 0.2066\n",
            "Epoch 223/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0901 - val_loss: 0.2056\n",
            "Epoch 224/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0913 - val_loss: 0.2062\n",
            "Epoch 225/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0899 - val_loss: 0.2118\n",
            "Epoch 226/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0899 - val_loss: 0.2156\n",
            "Epoch 227/1000\n",
            "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0895 - val_loss: 0.1982\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a1737a9a170>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=PATIENCE),# early stopping\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath=MODEL_FNAME_PATTERN, save_best_only=True) # save the best based on validation\n",
        "]\n",
        "\n",
        "unet = get_unet()\n",
        "unet.compile(optimizer=OPTIMISER, loss=LOSS)\n",
        "unet.fit(\n",
        "    x=full_train,\n",
        "    y=full_train_label,\n",
        "    validation_data=(full_val, full_val_label),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=N_EPOCHS,\n",
        "    callbacks=my_callbacks,\n",
        "    verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGcfrZCMjz4M"
      },
      "source": [
        "##Load the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fNsYJL7KnON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "541eb848-c7a2-4f4e-aa06-53accb32729f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 94 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "unet = get_unet(\n",
        "    img_size=(IMAGE_SIZE[1], IMAGE_SIZE[2]),\n",
        "    n_classes=N_CLASSES,\n",
        "    n_input_channels=N_INPUT_CHANNELS)\n",
        "unet.compile(optimizer=OPTIMISER, loss=LOSS)\n",
        "unet.load_weights('model.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwPzN0jrSm8r"
      },
      "source": [
        "##Prepare test data using the validation volumes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuRHLNYGkDFp"
      },
      "outputs": [],
      "source": [
        "def prepare_val_data(the_volumes, the_labels):\n",
        "  testing_volumes_processed = the_volumes.reshape([-1, IMAGE_SIZE[1], IMAGE_SIZE[2], 1])\n",
        "  testing_labels_processed = the_labels.reshape([-1, IMAGE_SIZE[1], IMAGE_SIZE[2], 1])\n",
        "\n",
        "  testing_labels_processed = tf.keras.utils.to_categorical(testing_labels_processed, num_classes=4)\n",
        "  testing_labels_processed = testing_labels_processed.astype('float32')\n",
        "\n",
        "\n",
        "  #print(testing_volumes_processed.shape)\n",
        "  #print(testing_labels_processed.shape)\n",
        "\n",
        "  return (testing_volumes_processed, testing_labels_processed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbJZUQyLqF4p"
      },
      "source": [
        "###Predict labels for test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItoY31x0K3r8"
      },
      "outputs": [],
      "source": [
        "def pred_val_data(testing_volumes_processed)  :\n",
        "  # creates probability map of each label for all volumes\n",
        "  prediction = unet.predict(x=testing_volumes_processed)\n",
        "\n",
        "  prediction = np.argmax(prediction, axis=3)\n",
        "\n",
        "  #plt.axis('off')\n",
        "  #plt.imshow(prediction[:, :, 150])\n",
        "\n",
        "  return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VU2XAj_wxgJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4cb0a67-a4f0-4c49-e901-1fa6d75e6554"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nprint(prediction.shape)\\nprint(testing_labels_processed.shape)\\nprint(testing_volumes_T1_processed.shape)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "\"\"\"\n",
        "print(prediction.shape)\n",
        "print(testing_labels_processed.shape)\n",
        "print(testing_volumes_T1_processed.shape)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Computing Dice, AVD and HD (Final)\n",
        "\n"
      ],
      "metadata": {
        "id": "5RHaF_LhpWXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_hausdorff_distance(in1, in2, label = 'all'):\n",
        "    in1=in1.squeeze()\n",
        "    in2=in2.squeeze()\n",
        "    hausdorff_distance_filter = sitk.HausdorffDistanceImageFilter()\n",
        "    if label == 'all':\n",
        "        # Hausdorff distance\n",
        "        hausdorff_distance_filter.Execute(in1, in2)\n",
        "    else:\n",
        "        in1_array  = in1 #sitk.GetArrayFromImage(in1)\n",
        "        in1_array = (in1_array == label) *1\n",
        "        in1_array = in1_array.astype('uint16')\n",
        "        img1 = sitk.GetImageFromArray(in1_array)\n",
        "\n",
        "        in2_array  = in2 #sitk.GetArrayFromImage(in2)\n",
        "        in2_array = (in2_array == label) *1\n",
        "        in2_array = in2_array.astype('uint16')\n",
        "        img2 = sitk.GetImageFromArray(in2_array)\n",
        "        # Hausdorff distance\n",
        "        hausdorff_distance_filter.Execute(img1, img2)\n",
        "    return hausdorff_distance_filter.GetHausdorffDistance()\n",
        "\n",
        "def compute_dice_coefficient(in1, in2, label  = 'all'):\n",
        "    in1=in1.squeeze()\n",
        "    in2=in2.squeeze()\n",
        "    if label=='all':\n",
        "        return 2 * np.sum( (in1>0) &  (in2>0) & (in1 == in2)) / (np.sum(in1 > 0) + np.sum(in2 > 0))\n",
        "    else:\n",
        "        return 2 * np.sum((in1 == label) & (in2 == label)) / (np.sum(in1 == label) + np.sum(in2 == label))\n",
        "\n",
        "def compute_volumentric_difference(in1, in2, label  = 'all'):\n",
        "    in1=in1.squeeze()\n",
        "    in2=in2.squeeze()\n",
        "    if label  == 'all':\n",
        "      #  vol_dif  = np.sum((in1 != in2) & (in1 !=0) & (in2 !=0))\n",
        "        return np.sum((in1 != in2)) / ((np.sum(in1 > 0) + np.sum(in2 > 0)))\n",
        "    else:\n",
        "        in1  = (in1 == label) * 1\n",
        "        in2  = (in2 == label) * 1\n",
        "        return np.sum((in1 != in2)) / ((np.sum(in1 > 0) + np.sum(in2 > 0)))"
      ],
      "metadata": {
        "id": "iFBnx17Bpa_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for cl in range(0,4,1):\n",
        "  overallDSC = np.zeros(N_CLASSES)\n",
        "  overall_Hausdorff = np.zeros(N_CLASSES)\n",
        "  overall_vol = np.zeros(N_CLASSES)\n",
        "\n",
        "  for i in range(0,validation_volumes.shape[0], 1):\n",
        "\n",
        "      testing_volumes_processed, testing_labels_processed = prepare_val_data(v_volumes[i], v_labels[i])\n",
        "      prediction = pred_val_data(testing_volumes_processed)\n",
        "\n",
        "      # cl = 2\n",
        "\n",
        "      cur_DSC = compute_dice_coefficient(prediction, v_labels[i], label=cl)\n",
        "      overallDSC = overallDSC + cur_DSC\n",
        "\n",
        "      cur_Hausdorff = compute_hausdorff_distance(prediction, v_labels[i], label=cl)\n",
        "      overall_Hausdorff = overall_Hausdorff + cur_Hausdorff\n",
        "\n",
        "      cur_vol = compute_volumentric_difference(prediction, v_labels[i], label=cl)\n",
        "      overall_vol = overall_vol + cur_vol\n",
        "\n",
        "      print(prediction.shape)\n",
        "      print(v_labels[i].shape)\n",
        "\n",
        "  #print(overall_Hausdorff)\n",
        "  overallDSC = overallDSC/validation_volumes.shape[0]\n",
        "  overall_Hausdorff = overall_Hausdorff/validation_volumes.shape[0]\n",
        "  overall_vol = overall_vol/validation_volumes.shape[0]\n",
        "\n",
        "  # for i in range(0,cl,1):\n",
        "  #print(\"Class {} - Dice Coefficient = {:.4f}\".format(cl, overallDSC[i]))\n",
        "  #print(\"Class {} - HD = {:.4f}\".format(cl, overall_Hausdorff[i]))\n",
        "  #print(\"Class {} - AVD = {:.4f}\".format(cl, overall_vol[i]))\n",
        "  print(\"Class {}\".format(cl))\n",
        "  print(\"\\tDice Coefficient = {:.4f}\".format(overallDSC[i]))\n",
        "  # print(\"\\tHD = {:.4f}\".format(overall_Hausdorff[i]))\n",
        "  # print(\"\\tAVD = {:.4f}\".format(overall_vol[i]))"
      ],
      "metadata": {
        "id": "8PrStjpepejb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d91fc5d-26f6-4975-abe9-923c3742a863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step\n",
            "(256, 128, 256)\n",
            "(256, 128, 256, 1)\n",
            "Class 0\n",
            "\tDice Coefficient = 0.9966\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "(256, 128, 256)\n",
            "(256, 128, 256, 1)\n",
            "Class 1\n",
            "\tDice Coefficient = 0.7488\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "(256, 128, 256)\n",
            "(256, 128, 256, 1)\n",
            "Class 2\n",
            "\tDice Coefficient = 0.8937\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "(256, 128, 256)\n",
            "(256, 128, 256, 1)\n",
            "Class 3\n",
            "\tDice Coefficient = 0.7539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3zTHEeiN4kE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e09bb416-de1f-4751-aa5d-ac158820e8c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nClass 0 - Dice Coefficient 0.9975\\nClass 1 - Dice Coefficient 0.8342\\nClass 2 - Dice Coefficient 0.9209\\nClass 3 - Dice Coefficient 0.8825\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# 2DUNet\n",
        "# batch size = 32, patient = 5, dropout=0.15, epoch = 50\n",
        "\"\"\"\n",
        "Class 0 - Dice Coefficient 0.9976\n",
        "Class 1 - Dice Coefficient 0.8288\n",
        "Class 2 - Dice Coefficient 0.9186\n",
        "Class 3 - Dice Coefficient 0.8765\n",
        "\"\"\"\n",
        "\n",
        "# batch size = 40, patient = 5, dropout=0.15, epoch = 50\n",
        "\"\"\"\n",
        "Class 0 - Dice Coefficient 0.9977\n",
        "Class 1 - Dice Coefficient 0.8261\n",
        "Class 2 - Dice Coefficient 0.9202\n",
        "Class 3 - Dice Coefficient 0.8790\n",
        "\"\"\"\n",
        "\n",
        "# batch size = 50, patient = 20, dropout=0.15, epoch = 200\n",
        "\"\"\"\n",
        "Class 0 - Dice Coefficient 0.9977\n",
        "Class 1 - Dice Coefficient 0.8261\n",
        "Class 2 - Dice Coefficient 0.9202\n",
        "Class 3 - Dice Coefficient 0.8790\n",
        "\"\"\"\n",
        "\n",
        "# batch size = 64, patient = 20, dropout=0.40, epoch = 200\n",
        "\"\"\"\n",
        "Class 0 - Dice Coefficient 0.9975\n",
        "Class 1 - Dice Coefficient 0.8342\n",
        "Class 2 - Dice Coefficient 0.9209\n",
        "Class 3 - Dice Coefficient 0.8825\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CipR5ZtUqSDC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}